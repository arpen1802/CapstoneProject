{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main algorithmic components of the character extraction phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ##show_image creates a normalized window to display the image and destroyes it after a random key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, name):\n",
    "    cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(name, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##img_shape returns the height and width of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_shape(img):\n",
    "    height, width = img.shape[0:2]\n",
    "    return height, widt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##edge_detection returns edges found with the Canny algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_detection(gray_img):\n",
    "    edges = cv2.Canny(gray_img, 170, 230, 5, L2gradient=False)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##compute_skew computes the rotation angle using the lines found with HoughLines transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_skew(img):\n",
    "    height, width = img_shape(img)\n",
    "    img = cv2.GaussianBlur(img,(3,3),0)\n",
    "    edges = edge_detection(img)\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi/180, 150)\n",
    "    new_lines = []\n",
    "    if not (lines is None):\n",
    "        for i in range(len(lines)):\n",
    "            for rho,theta in lines[i]:\n",
    "                a = np.cos(theta)\n",
    "                b = np.sin(theta)\n",
    "                x0 = a*rho\n",
    "                y0 = b*rho\n",
    "                x1 = int(x0 + 1000*(-b))\n",
    "                y1 = int(y0 + 1000*(a))\n",
    "                x2 = int(x0 - 1000*(-b))\n",
    "                y2 = int(y0 - 1000*(a))\n",
    "                cv2.line(img,(x1,y1),(x2,y2),(0, 255, 0),2)\n",
    "                new_lines.append([[x1, y1, x2, y2]])\n",
    "        angle = 0.0\n",
    "        nb_lines = len(new_lines)\n",
    "        for line in new_lines:\n",
    "            angle += math.atan2(line[0][3]*1.0 - line[0][1]*1.0,line[0][2]*1.0 - line[0][0]*1.0)\n",
    "        if(nb_lines > 0):\n",
    "            angle /= nb_lines*1.0\n",
    "    else:\n",
    "        angle = 0\n",
    "        \n",
    "    return (angle * 180.0 / np.pi - 180) if (angle * 180.0 / np.pi ) > 90 else (angle * 180.0 / np.pi )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##deskew uses the rotation angle calculated in the previous step and applies correction using Affine transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskew(img,angle = 0):\n",
    "    rows, cols = img_shape(img)\n",
    "    diam = round(math.sqrt(rows**2 + cols **2))\n",
    "    mat = np.ones((diam, diam), 'uint8')\n",
    "    y_offset = round((diam - cols) / 2)\n",
    "    x_offset = round((diam - rows) / 2)\n",
    "    mat[x_offset:x_offset + rows, y_offset:y_offset + cols] = img\n",
    "    non_zero_pixels = cv2.findNonZero(mat)\n",
    "    center, wh, theta = cv2.minAreaRect(non_zero_pixels)\n",
    "    root_mat = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "    rotated = cv2.warpAffine(mat, root_mat, (diam, diam), flags=cv2.INTER_LINEAR)\n",
    "    sizex = np.int0(wh[0])\n",
    "    sizey = np.int0(wh[1])\n",
    "    if theta > -45 :\n",
    "        temp = sizex\n",
    "        sizex= sizey\n",
    "        sizey= temp\n",
    "    return cv2.getRectSubPix(rotated, (sizey,sizex), center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##threshold uses Otsu algorithm to binarize the image, and then inverts it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(img):\n",
    "    img = cv2.GaussianBlur(img,(3,3),0)\n",
    "    ret,bin_img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    return bin_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##equal_roi_delta creates a new black roi and using roi defenition coordinates performs the last stage of character processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_roi_delta(lm, rm, um, dm, delta, mask):\n",
    "    if(dm - um > rm - lm):\n",
    "        if((dm - um - rm + lm)%2 == 0):\n",
    "            diff = int((dm - um - rm + lm) / 2)\n",
    "            roi = np.zeros(((dm-um + 2 * delta), (rm - lm + 2 * delta + 2 * diff)))\n",
    "            roi[delta : delta + dm - um, diff + delta : diff + delta + rm - lm] = mask[um : dm,lm : rm]\n",
    "        else:\n",
    "            diff = int((dm - um - rm + lm) / 2)\n",
    "            roi = np.zeros(((dm-um + 2 * delta), (rm - lm + 2 * delta + 2 * diff + 1)))\n",
    "            roi[delta : delta + dm - um, diff + delta + 1 : diff + delta + 1 + rm - lm] = mask[um : dm,lm : rm]\n",
    "    else:\n",
    "        if((dm - um - rm + lm)%2 == 0):\n",
    "            diff = int((rm - lm - dm + um) / 2)\n",
    "            roi = np.zeros(((dm-um + 2 * delta + 2 * diff), (rm - lm + 2 * delta)))\n",
    "            roi[delta + diff + 1: delta + diff + 1 + dm - um, delta: delta + rm - lm] = mask[um : dm,lm : rm]\n",
    "        else:\n",
    "            diff = int((rm - lm - dm + um) / 2)\n",
    "            roi = np.zeros(((dm-um + 2 * delta + 2 * diff + 1), (rm - lm + 2 * delta)))\n",
    "            roi[delta + diff + 1 : delta + diff + 1 + dm - um, delta: delta + rm - lm] = mask[um : dm,lm : rm]\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##connected_components labels the different components in the binarized and deskewed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_components(bin_img, filename):\n",
    "    num_labels, labels_im = cv2.connectedComponents(bin_img)\n",
    "    label_hue = np.uint8(179 * labels_im/np.max(labels_im))\n",
    "    blank_ch = 255 * np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "    labeled_img[label_hue == 0] = 0\n",
    "    count = 1\n",
    "    comp_dict = {}\n",
    "    lm_list = []\n",
    "    for label in range(2,num_labels):\n",
    "        mask = np.array(labels_im, dtype=np.uint8)\n",
    "        mask[labels_im == label] = 255\n",
    "        mask[labels_im != label] = 0\n",
    "        surface = bin_img.shape[0] * bin_img.shape[1]\n",
    "        if(np.sum(mask == 255) > int(0.001 * surface) and np.sum(mask == 255) < int(0.09 * surface)):\n",
    "            white_pixels = np.array(np.where(mask == 255))\n",
    "            um = white_pixels[:,0]\n",
    "            dm = white_pixels[:,-1]\n",
    "            white_pixels_T = np.array(np.where(mask.T == 255))\n",
    "            lm = white_pixels_T[:,0]\n",
    "            rm = white_pixels_T[:,-1]\n",
    "            delta = 5\n",
    "            if((float(dm[0] - um[0]) / float(rm[0] - lm[0])) >= 1):\n",
    "                roi = equal_roi_delta(lm[0], rm[0], um[0], dm[0], delta, mask)\n",
    "                if(np.sum(roi) != 0 and roi.shape[0] == roi.shape[1]):\n",
    "                    resized_roi = cv2.resize(roi, (28, 28))\n",
    "                    comp_dict.update({str(lm[0]) : resized_roi})\n",
    "                    lm_list.append(lm[0])\n",
    "    sort = sorted(lm_list)\n",
    "    for value in sort:\n",
    "        cv.imwrite(\"path\", comp_dict[str(value)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
